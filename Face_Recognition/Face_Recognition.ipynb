{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition\n",
    "\n",
    "One of the most important application used today of Computer Vision is Face Recognition, In this Notebook i will present two main applications of Face Recognition and build Face Unlock Systems. Many of the ideas presented here are from [FaceNet](https://arxiv.org/pdf/1503.03832.pdf) and from the Deep Learning Specilization \n",
    "\n",
    "Face recognition problems commonly fall into two categories: \n",
    "\n",
    "- **Face Verification** - \"is this the claimed person?\". For example, at some airports, you can pass through customs by letting a system scan your passport and then verifying that you (the person carrying the passport) are the correct person. A mobile phone that unlocks using your face is also using face verification. This is a 1:1 matching problem. \n",
    "- **Face Recognition** - \"who is this person?\". For example,an employee entering the office the system checkes that his face is in the database and he has access to pass and then opens the door for him This is a 1:K matching problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face Verification\n",
    "\n",
    "##### 1 - Smartphones Face Unlock\n",
    "\n",
    "- Most smartphones today use face verification to unlock the smartphone, when you setup face unlock on your phone the front facing camera takes a picture of your face and uses a Convolution neural network to learn an encoding vector for your face and saves this encoding in a database \n",
    "\n",
    "- So when someone tries to unlock your phone again the front faceing camera takes a new picture of the face it sees at that moment, computes an encoding for that picture and compare it with the previous encoding saved in the database if it's you the encodings will matche and unlocks your phone if not it keeps the phone locked\n",
    "\n",
    "#####  This system will be implemented in this notebook using Inception ConvNet Structure\n",
    "\n",
    "- The inception network uses a series of inception blocks as shown in figure 1\n",
    "- This network is implmented in keras in inception_blocks.py file and imported in this notebook checkout the implemntation if interested\n",
    "    \n",
    "<img src=\"images/inception_module.png\" style=\"width:500px;height:200px;\">\n",
    "<caption><center> <u> <font color='purple'> Figure 1 </u></center></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, ZeroPadding2D, Activation, Input, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.pooling import MaxPooling2D, AveragePooling2D\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers.core import Lambda, Flatten, Dense\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.engine.topology import Layer\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from fr_utils import *\n",
    "from inception_blocks import *\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.set_printoptions(threshold=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's Call our Model from inception_blocks.py\n",
    "\n",
    "- This network uses 96x96 dimensional RGB images as its input. Specifically, inputs a face image (or batch of $m$ face images) as a tensor of shape $(m, n_C, n_H, n_W) = (m, 3, 96, 96)$ \n",
    "- It outputs a matrix of shape $(m, 128)$ that encodes each input face image into a 128-dimensional vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Lambada\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Total Params: 3743280\n"
     ]
    }
   ],
   "source": [
    "FRmodel = faceRecoModel(input_shape=(3, 96, 96));\n",
    "print(\"Total Params:\", FRmodel.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Triplet Loss\n",
    "\n",
    "To train the Model we will use the Triplet Loss Function as measure for how good the model does\n",
    "\n",
    "Training will use triplets of images $(A, P, N)$:  \n",
    "\n",
    "- A is an \"Anchor\" image--a picture of a person. \n",
    "- P is a \"Positive\" image--a picture of the same person as the Anchor image.\n",
    "- N is a \"Negative\" image--a picture of a different person than the Anchor image.\n",
    "\n",
    "These triplets are picked from our training dataset. We will write $(A^{(i)}, P^{(i)}, N^{(i)})$ to denote the $i$-th training example. \n",
    "\n",
    "If our Phone unlock system has an Image A of a Person in the setup and took a new picture of the Person P when trying to unlock the phone We'd like to train the model to make sure that an image $A^{(i)}$ of an individual is closer and similar to the Positive image $P^{(i)}$ than to the Negative image $N^{(i)}$) by at least a margin $\\alpha$:\n",
    "\n",
    "$$\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2 + \\alpha < \\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2$$\n",
    "\n",
    "So The Model will minimize the following \"triplet cost\":\n",
    "\n",
    "$$\\mathcal{J} = \\sum^{m}_{i=1} \\large[ \\small \\underbrace{\\mid \\mid f(A^{(i)}) - f(P^{(i)}) \\mid \\mid_2^2}_\\text{(1)} - \\underbrace{\\mid \\mid f(A^{(i)}) - f(N^{(i)}) \\mid \\mid_2^2}_\\text{(2)} + \\alpha \\large ] \\small_+Â \\tag{1}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred, alpha = 0.2):\n",
    "    \"\"\"\n",
    "    Implementation of the triplet loss Cost as defined in (1)\n",
    "    \n",
    "    Arguments:\n",
    "    y_true -- true labels, required when you define a loss in Keras\n",
    "    y_pred -- python list containing three objects:\n",
    "            anchor -- the encodings for the anchor images, of shape (None, 128)\n",
    "            positive -- the encodings for the positive images, of shape (None, 128)\n",
    "            negative -- the encodings for the negative images, of shape (None, 128)\n",
    "    \n",
    "    Returns:\n",
    "    loss -- real number, value of the loss\n",
    "    \"\"\"\n",
    "    \n",
    "    anchor , positive, negative = y_pred[0], y_pred[1], y_pred[2]\n",
    "    \n",
    "    #measures how similar is the Anchor image saved in the database to a positive image of a person\n",
    "    pos_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,positive)), axis=-1, keepdims=True)\n",
    "    #measures how similar is the anchor image to a negative image of different person\n",
    "    neg_dist = tf.reduce_sum(tf.square(tf.subtract(anchor,negative)), axis=-1, keepdims=True)\n",
    "    \n",
    "    basic_loss = pos_dist + alpha - neg_dist\n",
    "    \n",
    "    loss = tf.reduce_sum(tf.maximum(basic_loss,0)) # The Final Cost J\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model is trained by minimizing this triplet loss, Since Training requires a lot of data and a lot of computation and time it's common practice in deep learning to use pre-trained weights and do Transfer-Learning, when building our system we don't want the user to experinece this training computation cost to setup face-unlock so we will use pre-trained weights.\n",
    "\n",
    "We train a model for face-unlock on a very large dataset of faces to minimize the triplet loss on different machine that handles the computation cost and save the model weights and load it on the smartphone thus we already have neural network that know how to learn from faces, when a user setup the face-unlock we might further-train on images of his face if we want to further optimize our algorithim \n",
    "\n",
    "so in the next cell i load pre-trained weights on a very large datasets of faces and we will use it to further train the model \n",
    "\n",
    "We will use adam Algorithim for optimization and the Triplet loss function we defined and accuracy as measure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRmodel.compile(optimizer = 'adam', loss = triplet_loss, metrics = ['accuracy'])\n",
    "load_weights_from_FaceNet(FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next We will define a function that maps images into encodings using our defined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_encoding(image_path, model):\n",
    "    img1 = cv2.imread(image_path, 1)\n",
    "    img = img1[...,::-1]\n",
    "    img = np.around(np.transpose(img, (2,0,1))/255.0, decimals=12)\n",
    "    x_train = np.array([img])\n",
    "    embedding = model.predict_on_batch(x_train)\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face Unlock\n",
    "Now let's Build our Face Unlock System\n",
    "\n",
    "Younes tried To setup face-unlock on his Smartphone for the first time \n",
    "\n",
    "- The phone took the following picture of younes face \n",
    "\n",
    "<img src=\"images/younes.jpg\" style=\"width:100px;height:100px;\">\n",
    "\n",
    "- for this picture in the next cell the algorithim will compute an encoding vector for younes face we call it True_encoding\n",
    "- we will save this encoding in a database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "\n",
    "database[\"younes\"] = img_to_encoding(\"images/younes.jpg\", FRmodel) #true Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now When someone pickup the Phone\n",
    "\n",
    "- The Camera will take a picture of the face it sees and saves it in a directory img_path\n",
    "- We will load that picture from that path (img_path) and compute an encoding for it using our model we will call it new_encoding\n",
    "- Next We will Compare this New_endcoding with The True_encoding we have in our database \n",
    "- If the two encodings are similar and the distance is less then some threshold for example 0.7 the phone will unlock\n",
    "- if the two encoding are less similar and the distance are higher than this threshold the phone will keep locked\n",
    "\n",
    "let's implement the following system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_unlock(image_path,database,model):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    image_path -- path to an image\n",
    "    database -- python dictionary mapping names of allowed people's names (strings) to their encodings (vectors).\n",
    "    model --  Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "    dist -- distance between the image_path and the image of \"identity\" in the database.\n",
    "    phone_unlock -- True, if the Phone should unlock. False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    #considring we setup the phone with some code to take pictures and saves them in a directory img_path\n",
    "    encoding = img_to_encoding(image_path, model)\n",
    "    dist = np.linalg.norm(np.subtract(encoding,database[\"younes\"]),ord=2)   \n",
    "    \n",
    "    if dist < 0.7:\n",
    "        print('Phone Unlocked!')\n",
    "        phone_unlock = True\n",
    "    else:\n",
    "        print('Only younes is Allowed to Unlock The Phone')\n",
    "        phone_unlock = False\n",
    "        \n",
    "    return dist,phone_unlock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone picked up the phone and tried to unlock it, the front faceing camera took the following picture for him, the picture was saved in the following directory \"images/camera_0.jpg\" let's see what our model will do\n",
    "\n",
    "<img src=\"images/camera_0.jpg\" style=\"width:100px;height:100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phone Unlocked!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.65938383, True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_unlock(\"images/camera_0.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone picked up the phone and tried to unlock it, the front faceing camera took the following picture for him, the picture was saved in the following directory  \"images/camera_2.jpg\" let's see what our model will do\n",
    "\n",
    "<img src=\"images/camera_2.jpg\" style=\"width:100px;height:100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only younes is Allowed to Unlock The Phone\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.0097818, False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_unlock(\"images/camera_2.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Face Recognition\n",
    "\n",
    "Some company wants to build Face-Recongition System that only authorized employees can enter the building, one way is to use id card for each employee, an employee swips his id at the door and it opens for him\n",
    "\n",
    "Deep learning allows us to get rid of id-cards and use more secure systems because id-cards could be stolen so we will build a face-recognition system, we will use the same idea used to build the phone-unlock and use the same network\n",
    "\n",
    "Setting up:\n",
    "- when setting up the system for the first time the camera will take a picture for each authorized employee.\n",
    "- the model will compute an ecnoding for each picture for each employee using img_to_encoding()\n",
    "- the encodings will be saved in a database each employee name with his corrsponding encoding\n",
    "- when someone shows up at the door and tries to enter the building the system will take a new picture for him and saves it in directory img_path\n",
    "- the system will load that picture from img_path and compute an encoding for it \n",
    "- we will compare this new_encoding with all of the encodings we have in the database and see which one is the closest to it and calculate the distance \n",
    "- we will check if the distance is less than some threshold for example 0.7 to make sure if so then unlock the door, if it's higher than this person is not in the database of authorized persons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's create a database for all the authorized employees\n",
    "a picture is taken for each person with the camera and using our model we will compute an encoding for it and save it in databae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = {}\n",
    "database[\"danielle\"] = img_to_encoding(\"images/danielle.png\", FRmodel)\n",
    "database[\"tian\"] = img_to_encoding(\"images/tian.jpg\", FRmodel)\n",
    "database[\"kian\"] = img_to_encoding(\"images/kian.jpg\", FRmodel)\n",
    "database[\"dan\"] = img_to_encoding(\"images/dan.jpg\", FRmodel)\n",
    "database[\"sebastiano\"] = img_to_encoding(\"images/sebastiano.jpg\", FRmodel)\n",
    "database[\"bertrand\"] = img_to_encoding(\"images/bertrand.jpg\", FRmodel)\n",
    "database[\"kevin\"] = img_to_encoding(\"images/kevin.jpg\", FRmodel)\n",
    "database[\"benoit\"] = img_to_encoding(\"images/benoit.jpg\", FRmodel)\n",
    "database[\"arnaud\"] = img_to_encoding(\"images/arnaud.jpg\", FRmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_recognition(img_path, database, model):\n",
    "    \"\"\"\n",
    "    Implements face recognition for the office by finding who is the person on the image_path image.\n",
    "    \n",
    "    Arguments:\n",
    "    image_path -- path to an image\n",
    "    database -- database containing image encodings along with the name of the person on the image\n",
    "    model -- your Inception model instance in Keras\n",
    "    \n",
    "    Returns:\n",
    "    min_dist -- the minimum distance between image_path encoding and the encodings from the database\n",
    "    identity -- string, the name prediction for the person on image_path\n",
    "    \"\"\"\n",
    "        \n",
    "    encoding = img_to_encoding(img_path, model)\n",
    "    min_dist = 100\n",
    "    \n",
    "    for (name,enc) in database.items():\n",
    "        dist = np.linalg.norm(encoding - enc,ord=2)\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            identity = name\n",
    "    if min_dist < 0.7:\n",
    "        print(\"door unlocked it's {}\".format(identity))\n",
    "    else:\n",
    "        print(\"You are not Authorized to enter\")\n",
    "        identity = 'Unknown'\n",
    "        \n",
    "    return min_dist,identity\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This All The images of the authorized persons taken in the setup and we have their encoding saved in the database\n",
    "\n",
    "<table><tr><td><img src='images/danielle.png'></td><td><img src='images/benoit.jpg'></td><td><img src='images/tian.jpg'></td></tr></table>\n",
    "<table><tr><td><img src='images/arnaud.jpg'></td><td><img src='images/kian.jpg'></td><td><img src='images/dan.jpg'></td></tr></table>\n",
    "<table><tr><td><img src='images/sebastiano.jpg'></td><td><img src='images/bertrand.jpg'></td><td><img src='images/kevin.jpg'></td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone showed up at the door and tried to enter the building, the camera took the following picture for him, the picture was saved in the following directory  \"images/camera_1.jpg\" let's see what our model will do\n",
    "\n",
    "<img src=\"images/camera_1.jpg\" style=\"width:100px;height:100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "door unlocked it's bertrand\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.46768862, 'bertrand')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_recognition(\"images/camera_1.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone showed up at the door and tried to enter the building, the camera took the following picture for him, the picture was saved in the following directory  \"images/camera_4.jpg\" let's see what our model will do\n",
    "\n",
    "<img src=\"images/camera_4.jpg\" style=\"width:100px;height:100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "door unlocked it's dan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.25046661, 'dan')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_recognition(\"images/camera_4.jpg\", database, FRmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Someone showed up at the door and tried to enter the building, the camera took the following picture for him, the picture was saved in the following directory  \"images/camera_0.jpg\" let's see what our model will do\n",
    "\n",
    "<img src=\"images/camera_0.jpg\" style=\"width:100px;height:100px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are not Authorized to enter\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7455134, 'Unknown')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_recognition(\"images/camera_0.jpg\", database, FRmodel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
